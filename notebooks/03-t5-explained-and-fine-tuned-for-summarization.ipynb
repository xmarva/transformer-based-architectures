{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate nltk rouge_score py7zr\n",
    "!pip install -q accelerate\n",
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    get_scheduler,\n",
    "    set_seed\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import wandb\n",
    "import gc\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b8d59516b4415a999a044211ab1707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a17b480fd64595b1ededa45fee7e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xsum.py:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822ded68b6124f3e8d57cc13fc4f15b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6ba57e0d174f35a6929d7af18a62c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/16.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd7f9bcf8964034b9e221bddf57d272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/17.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c524939d0cba481486456b86cf56ecb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921694c00144462baadf416cd0124b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38630bb19f314686bcda697a47653ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"EdinburghNLP/xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 204045\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 11332\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 11334\n",
      "    })\n",
      "})\n",
      "Train set size: 204045\n",
      "Validation set size: 11332\n",
      "Test set size: 11334\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset loaded: {dataset}\")\n",
    "print(f\"Train set size: {len(dataset['train'])}\")\n",
    "print(f\"Validation set size: {len(dataset['validation'])}\")\n",
    "print(f\"Test set size: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample document:\n",
      "The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\n",
      "Repair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\n",
      "Trains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\n",
      "Many businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\n",
      "First Minister Nicola Sturgeon visited the area to inspect the damage.\n",
      "The water...\n",
      "\n",
      "Sample summary:\n",
      "Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "print(\"\\nSample document:\")\n",
    "print(sample[\"document\"][:500] + \"...\\n\")\n",
    "print(\"Sample summary:\")\n",
    "print(sample[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(dataset, split=\"train\", num_samples=1000):\n",
    "    \"\"\"Analyze document and summary lengths in the dataset.\"\"\"\n",
    "    if num_samples > len(dataset[split]):\n",
    "        num_samples = len(dataset[split])\n",
    "    \n",
    "    doc_lengths = []\n",
    "    summary_lengths = []\n",
    "    compression_ratios = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        doc = dataset[split][i][\"document\"]\n",
    "        summary = dataset[split][i][\"summary\"]\n",
    "        \n",
    "        doc_words = len(doc.split())\n",
    "        summary_words = len(summary.split())\n",
    "        \n",
    "        doc_lengths.append(doc_words)\n",
    "        summary_lengths.append(summary_words)\n",
    "        \n",
    "        if doc_words > 0:\n",
    "            compression_ratios.append(summary_words / doc_words)\n",
    "    \n",
    "    return {\n",
    "        \"doc_lengths\": {\n",
    "            \"mean\": np.mean(doc_lengths),\n",
    "            \"median\": np.median(doc_lengths),\n",
    "            \"min\": np.min(doc_lengths),\n",
    "            \"max\": np.max(doc_lengths),\n",
    "        },\n",
    "        \"summary_lengths\": {\n",
    "            \"mean\": np.mean(summary_lengths),\n",
    "            \"median\": np.median(summary_lengths),\n",
    "            \"min\": np.min(summary_lengths),\n",
    "            \"max\": np.max(summary_lengths),\n",
    "        },\n",
    "        \"compression_ratio\": {\n",
    "            \"mean\": np.mean(compression_ratios),\n",
    "            \"median\": np.median(compression_ratios),\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Analysis:\n",
      "Document length (words): {'mean': 361.979, 'median': 289.0, 'min': 11, 'max': 2694}\n",
      "Summary length (words): {'mean': 21.101, 'median': 21.0, 'min': 1, 'max': 48}\n",
      "Compression ratio: {'mean': 0.10330915428072975, 'median': 0.07246376811594203}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_dataset(dataset)\n",
    "print(\"\\nDataset Analysis:\")\n",
    "print(f\"Document length (words): {analysis['doc_lengths']}\")\n",
    "print(f\"Summary length (words): {analysis['summary_lengths']}\")\n",
    "print(f\"Compression ratio: {analysis['compression_ratio']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"t5-base\"  # Options: t5-small, t5-base, t5-large, t5-3b, t5-11b\n",
    "MAX_SOURCE_LENGTH = 512 \n",
    "MAX_TARGET_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb52a25994443588f2f51f9f04fa7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0069a7a32e824f6ea545731b659bd729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2421b2a5f64641c78920094e346a426f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: t5-base\n",
      "Vocabulary size: 32000\n",
      "Maximum source length: 512\n",
      "Maximum target length: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"Maximum source length: {MAX_SOURCE_LENGTH}\")\n",
    "print(f\"Maximum target length: {MAX_TARGET_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"summarize: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset for T5 fine-tuning.\n",
    "    T5 was trained with the prefix format, so we add \"summarize: \" before the input text.\n",
    "    \"\"\"\n",
    "    # Add prefix to the inputs\n",
    "    inputs = [PREFIX + doc for doc in examples[\"document\"]]\n",
    "    \n",
    "    # Tokenize inputs and targets\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_SOURCE_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"summary\"],\n",
    "            max_length=MAX_TARGET_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    # Replace padding token id with -100 so it's ignored in loss calculation\n",
    "    for i in range(len(model_inputs[\"labels\"])):\n",
    "        model_inputs[\"labels\"][i] = [\n",
    "            -100 if token == tokenizer.pad_token_id else token \n",
    "            for token in model_inputs[\"labels\"][i]\n",
    "        ]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1405058a18a041bfa37058ec0f2f87f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing dataset:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85aa850dbd264fe7aaf4fa997034fb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing dataset:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2781f5294fb419cac87e37231efe440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing dataset:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessing completed.\n",
      "Columns in processed dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Preprocessing dataset\",\n",
    ")\n",
    "\n",
    "print(\"Dataset preprocessing completed.\")\n",
    "print(f\"Columns in processed dataset: {tokenized_datasets['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbd18558f374e58bc2b65509b7996bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332d8ef9383640c89b0ee0dc0b5febe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: t5-base\n",
      "Number of parameters: 222,903,552\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "print(f\"Model loaded: {MODEL_NAME}\")\n",
    "print(f\"Number of parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gradient_accumulation_steps = 4\n",
    "effective_batch_size = batch_size * gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective batch size: 32\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"./results/{MODEL_NAME}-xsum\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,  # Mixed precision training\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    generation_max_length=MAX_TARGET_LENGTH,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_steps=500,\n",
    "    report_to=\"none\",  # Set to \"wandb\" if using Weights & Biases\n",
    ")\n",
    "\n",
    "print(f\"Effective batch size: {effective_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf0c7207b4c46369948087861cbb85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"Compute ROUGE metrics for evaluation.\"\"\"\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    # Decode generated summaries\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    \n",
    "    # Extract median scores\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38168/1485828738.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_training_loop(model, tokenizer, train_dataset, val_dataset, num_epochs=3):\n",
    "    \"\"\"\n",
    "    Custom training loop with linear scheduler with warmup.\n",
    "    This demonstrates more control over the training process compared to using Trainer.\n",
    "    \"\"\"\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.optim import AdamW\n",
    "    \n",
    "    # Prepare data loaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "    warmup_steps = int(0.1 * total_steps)  # 10% of total steps for warmup\n",
    "    \n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=\"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    progress_bar = tqdm(range(total_steps))\n",
    "    global_step = 0\n",
    "    best_rouge1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            # Move batch to device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Scale loss for gradient accumulation\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            \n",
    "            if (global_step + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            global_step += 1\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            # Log training loss\n",
    "            if global_step % 100 == 0:\n",
    "                print(f\"Step {global_step}: Loss = {train_loss / (global_step % len(train_dataloader) or 1)}\")\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Average training loss: {avg_train_loss}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        original_references = []\n",
    "        \n",
    "        # Get actual reference summaries for proper evaluation\n",
    "        for idx, batch in enumerate(val_dataloader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                val_loss += outputs.loss.item()\n",
    "                \n",
    "                # Generate predictions\n",
    "                generated_tokens = model.generate(\n",
    "                    batch[\"input_ids\"],\n",
    "                    attention_mask=batch[\"attention_mask\"],\n",
    "                    max_length=MAX_TARGET_LENGTH,\n",
    "                    num_beams=4,\n",
    "                    length_penalty=0.6,\n",
    "                    early_stopping=True,\n",
    "                )\n",
    "                \n",
    "                # Decode generated tokens and labels\n",
    "                decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "                all_preds.extend(decoded_preds)\n",
    "                \n",
    "                # Replace -100 in labels with pad token id for decoding\n",
    "                labels = batch[\"labels\"].detach().cpu().numpy()\n",
    "                labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "                decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "                all_labels.extend(decoded_labels)\n",
    "        \n",
    "        # Process predictions and references for ROUGE\n",
    "        processed_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in all_preds]\n",
    "        processed_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in all_labels]\n",
    "        \n",
    "        # Compute metrics directly with processed text\n",
    "        rouge_result = rouge_metric.compute(\n",
    "            predictions=processed_preds,\n",
    "            references=processed_labels,\n",
    "            use_stemmer=True,\n",
    "        )\n",
    "        \n",
    "        # Extract and format scores\n",
    "        metrics = {k: round(v * 100, 4) for k, v in rouge_result.items()}\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        print(f\"ROUGE scores: {metrics}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if metrics[\"rouge1\"] > best_rouge1:\n",
    "            best_rouge1 = metrics[\"rouge1\"]\n",
    "            # Save model checkpoint\n",
    "            torch.save(model.state_dict(), f\"./checkpoint_epoch_{epoch+1}.pt\")\n",
    "            print(f\"New best model saved with ROUGE-1: {best_rouge1}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7fd32ffefc4417949dcfad7bc1f8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100: Loss = 0.846891377568245\n",
      "Step 200: Loss = 0.8476318830251693\n",
      "Step 300: Loss = 0.8447808194160461\n",
      "Step 400: Loss = 0.8415350131690502\n",
      "Step 500: Loss = 0.833954271197319\n",
      "Step 600: Loss = 0.8264095644156139\n",
      "Step 700: Loss = 0.8190177027668272\n",
      "Step 800: Loss = 0.8100372513383627\n",
      "Step 900: Loss = 0.8013554637961917\n",
      "Step 1000: Loss = 0.7927718778848648\n",
      "Step 1100: Loss = 0.7841565965522419\n",
      "Step 1200: Loss = 0.7749715100228787\n",
      "Step 1300: Loss = 0.7669051455534421\n",
      "Step 1400: Loss = 0.7590381034782955\n",
      "Step 1500: Loss = 0.7510470645427704\n",
      "Step 1600: Loss = 0.7437663317471742\n",
      "Step 1700: Loss = 0.7373195025850745\n",
      "Step 1800: Loss = 0.7316151083509127\n",
      "Step 1900: Loss = 0.7258688671808494\n",
      "Step 2000: Loss = 0.7201008120030165\n",
      "Step 2100: Loss = 0.7148372542432376\n",
      "Step 2200: Loss = 0.710067094726996\n",
      "Step 2300: Loss = 0.7054087737850521\n",
      "Step 2400: Loss = 0.7008772186934948\n",
      "Step 2500: Loss = 0.6966613448023796\n",
      "Step 2600: Loss = 0.6927011335698458\n",
      "Step 2700: Loss = 0.6891120425418571\n",
      "Step 2800: Loss = 0.6855224125406572\n",
      "Step 2900: Loss = 0.6818338675437302\n",
      "Step 3000: Loss = 0.6787017505367597\n",
      "Step 3100: Loss = 0.6758170679692299\n",
      "Step 3200: Loss = 0.6731401556823403\n",
      "Step 3300: Loss = 0.6703901930288835\n",
      "Step 3400: Loss = 0.6678651432955967\n",
      "Step 3500: Loss = 0.6652868279303823\n",
      "Step 3600: Loss = 0.6631129527588685\n",
      "Step 3700: Loss = 0.6610117952968623\n",
      "Step 3800: Loss = 0.6588369402838381\n",
      "Step 3900: Loss = 0.6567577131971335\n",
      "Step 4000: Loss = 0.6546914713457227\n",
      "Step 4100: Loss = 0.6528365210934383\n",
      "Step 4200: Loss = 0.6509867281147412\n",
      "Step 4300: Loss = 0.6491353020418522\n",
      "Step 4400: Loss = 0.6474883255430243\n",
      "Step 4500: Loss = 0.6458461688028442\n",
      "Step 4600: Loss = 0.6441456009965876\n",
      "Step 4700: Loss = 0.6428218758803733\n",
      "Step 4800: Loss = 0.6414323661414285\n",
      "Step 4900: Loss = 0.640037981624506\n",
      "Step 5000: Loss = 0.6386448015809059\n",
      "Step 5100: Loss = 0.6371713749567668\n",
      "Step 5200: Loss = 0.6357210764575463\n",
      "Step 5300: Loss = 0.6343400544040608\n",
      "Step 5400: Loss = 0.6329671576232822\n",
      "Step 5500: Loss = 0.6318840802474456\n",
      "Step 5600: Loss = 0.6305695143075926\n",
      "Step 5700: Loss = 0.6294053618060915\n",
      "Step 5800: Loss = 0.62829342521984\n",
      "Step 5900: Loss = 0.6270191745687339\n",
      "Step 6000: Loss = 0.6260386930257082\n",
      "Step 6100: Loss = 0.6250831592473828\n",
      "Step 6200: Loss = 0.6242470859952511\n",
      "Step 6300: Loss = 0.6231715481669183\n",
      "Step 6400: Loss = 0.6220738845178857\n",
      "Step 6500: Loss = 0.6212414574439709\n",
      "Step 6600: Loss = 0.620270978808403\n",
      "Step 6700: Loss = 0.6192238769869306\n",
      "Step 6800: Loss = 0.6183107220030882\n",
      "Step 6900: Loss = 0.6174708202394886\n",
      "Step 7000: Loss = 0.6165572808257171\n",
      "Step 7100: Loss = 0.6156751801052563\n",
      "Step 7200: Loss = 0.6149122563997904\n",
      "Step 7300: Loss = 0.6140289603561572\n",
      "Step 7400: Loss = 0.6132464837262759\n",
      "Step 7500: Loss = 0.6124287373741468\n",
      "Step 7600: Loss = 0.6117523274845199\n",
      "Step 7700: Loss = 0.6110609130309774\n",
      "Step 7800: Loss = 0.6103791865286154\n",
      "Step 7900: Loss = 0.6095956168899054\n",
      "Step 8000: Loss = 0.6088956813178956\n",
      "Step 8100: Loss = 0.6081744665312179\n",
      "Step 8200: Loss = 0.6075633646584139\n",
      "Step 8300: Loss = 0.6068811581041439\n",
      "Step 8400: Loss = 0.6061515107786372\n",
      "Step 8500: Loss = 0.6054296964862768\n",
      "Step 8600: Loss = 0.6047497512677381\n",
      "Step 8700: Loss = 0.6041759532895582\n",
      "Step 8800: Loss = 0.6035752049969001\n",
      "Step 8900: Loss = 0.603045231254583\n",
      "Step 9000: Loss = 0.6025267871187793\n",
      "Step 9100: Loss = 0.6020190056175976\n",
      "Step 9200: Loss = 0.6014221317936544\n",
      "Step 9300: Loss = 0.6008515510668037\n",
      "Step 9400: Loss = 0.6001704803299397\n",
      "Step 9500: Loss = 0.5996373567392952\n",
      "Step 9600: Loss = 0.5991387024149298\n",
      "Step 9700: Loss = 0.5986698086482962\n",
      "Step 9800: Loss = 0.5981538410636843\n",
      "Step 9900: Loss = 0.597610621187422\n",
      "Step 10000: Loss = 0.5971918538421392\n",
      "Step 10100: Loss = 0.5965696818020084\n",
      "Step 10200: Loss = 0.5961305630323933\n",
      "Step 10300: Loss = 0.59557876675453\n",
      "Step 10400: Loss = 0.5951564391473165\n",
      "Step 10500: Loss = 0.5946519599613689\n",
      "Step 10600: Loss = 0.5941272691735682\n",
      "Step 10700: Loss = 0.5937332646423411\n",
      "Step 10800: Loss = 0.5932446634962603\n",
      "Step 10900: Loss = 0.592830302603201\n",
      "Step 11000: Loss = 0.5923583242730661\n",
      "Step 11100: Loss = 0.5919136689509358\n",
      "Step 11200: Loss = 0.5914828688731151\n",
      "Step 11300: Loss = 0.5910456307799415\n",
      "Step 11400: Loss = 0.5906570638977645\n",
      "Step 11500: Loss = 0.5901572938950166\n",
      "Step 11600: Loss = 0.5897802764382856\n",
      "Step 11700: Loss = 0.5893705924122762\n",
      "Step 11800: Loss = 0.5888864039819119\n",
      "Step 11900: Loss = 0.5885073127866793\n",
      "Step 12000: Loss = 0.5881692075009147\n",
      "Step 12100: Loss = 0.5877664755346361\n",
      "Step 12200: Loss = 0.5874100857753246\n",
      "Step 12300: Loss = 0.5869969537708818\n",
      "Step 12400: Loss = 0.5866363868549946\n",
      "Step 12500: Loss = 0.586274163043499\n",
      "Step 12600: Loss = 0.5859079717809246\n",
      "Step 12700: Loss = 0.5855844790236218\n",
      "Step 12800: Loss = 0.5851896277279593\n",
      "Step 12900: Loss = 0.5847561214182728\n",
      "Step 13000: Loss = 0.5844548858450009\n",
      "Step 13100: Loss = 0.5840811623826282\n",
      "Step 13200: Loss = 0.5837165487038367\n",
      "Step 13300: Loss = 0.5833863172338422\n",
      "Step 13400: Loss = 0.5831041574344706\n",
      "Step 13500: Loss = 0.5827155679839628\n",
      "Step 13600: Loss = 0.5824154113715185\n",
      "Step 13700: Loss = 0.5820755182717838\n",
      "Step 13800: Loss = 0.581756073396275\n",
      "Step 13900: Loss = 0.5813749395578885\n",
      "Step 14000: Loss = 0.5810079873161657\n",
      "Step 14100: Loss = 0.5806947774202266\n",
      "Step 14200: Loss = 0.5803664340834382\n",
      "Step 14300: Loss = 0.5801037280522027\n",
      "Step 14400: Loss = 0.5797770942623417\n",
      "Step 14500: Loss = 0.5795442959152419\n",
      "Step 14600: Loss = 0.5792701624293033\n",
      "Step 14700: Loss = 0.5789880054195722\n",
      "Step 14800: Loss = 0.5787662198032076\n",
      "Step 14900: Loss = 0.5784400228445962\n",
      "Step 15000: Loss = 0.5781533595740795\n",
      "Step 15100: Loss = 0.5778112226724624\n",
      "Step 15200: Loss = 0.5774499975889921\n",
      "Step 15300: Loss = 0.5771648057808284\n",
      "Step 15400: Loss = 0.576879582590871\n",
      "Step 15500: Loss = 0.5766315011343648\n",
      "Step 15600: Loss = 0.5763876575957506\n",
      "Step 15700: Loss = 0.5761032587973176\n",
      "Step 15800: Loss = 0.5758425610257855\n",
      "Step 15900: Loss = 0.5756083683041656\n",
      "Step 16000: Loss = 0.5753027870543301\n",
      "Step 16100: Loss = 0.5750125638094749\n",
      "Step 16200: Loss = 0.5747812060239138\n",
      "Step 16300: Loss = 0.5745671657093463\n",
      "Step 16400: Loss = 0.5742487962362243\n",
      "Step 16500: Loss = 0.5740368122097218\n",
      "Step 16600: Loss = 0.5738045181190393\n",
      "Step 16700: Loss = 0.5735023286867285\n",
      "Step 16800: Loss = 0.5732282717703354\n",
      "Step 16900: Loss = 0.5729184163586628\n",
      "Step 17000: Loss = 0.5727089792490005\n",
      "Step 17100: Loss = 0.5724390003398845\n",
      "Step 17200: Loss = 0.5722204277595115\n",
      "Step 17300: Loss = 0.5719730439816596\n",
      "Step 17400: Loss = 0.571709380982251\n",
      "Step 17500: Loss = 0.571513157241685\n",
      "Step 17600: Loss = 0.5712903725711459\n",
      "Step 17700: Loss = 0.5710637679022584\n",
      "Step 17800: Loss = 0.5708065774434068\n",
      "Step 17900: Loss = 0.5705633654957377\n",
      "Step 18000: Loss = 0.5702589868141545\n",
      "Step 18100: Loss = 0.5700446065782842\n",
      "Step 18200: Loss = 0.5697910805046559\n",
      "Step 18300: Loss = 0.5695151745914762\n",
      "Step 18400: Loss = 0.5693382965546587\n",
      "Step 18500: Loss = 0.5690961931815018\n",
      "Step 18600: Loss = 0.5688743241147328\n",
      "Step 18700: Loss = 0.568732645953084\n",
      "Step 18800: Loss = 0.5685492516721182\n",
      "Step 18900: Loss = 0.5683402511004417\n",
      "Step 19000: Loss = 0.5681795679268085\n",
      "Step 19100: Loss = 0.56796505807582\n",
      "Step 19200: Loss = 0.5677145828135932\n",
      "Step 19300: Loss = 0.567509414436286\n",
      "Step 19400: Loss = 0.5672688105733125\n",
      "Step 19500: Loss = 0.5670804535257511\n",
      "Step 19600: Loss = 0.5669262082418617\n",
      "Step 19700: Loss = 0.5666949071103546\n",
      "Step 19800: Loss = 0.5664803780660485\n",
      "Step 19900: Loss = 0.5662709962797524\n",
      "Step 20000: Loss = 0.5661085376620293\n",
      "Step 20100: Loss = 0.5659132058836928\n",
      "Step 20200: Loss = 0.5656912743499374\n",
      "Step 20300: Loss = 0.5655332847416694\n",
      "Step 20400: Loss = 0.5653195625441332\n",
      "Step 20500: Loss = 0.5650944855067788\n",
      "Step 20600: Loss = 0.5648786242248364\n",
      "Step 20700: Loss = 0.5646827097100336\n",
      "Step 20800: Loss = 0.5645051637564141\n",
      "Step 20900: Loss = 0.564364662449896\n",
      "Step 21000: Loss = 0.5641724905698072\n",
      "Step 21100: Loss = 0.5640067432728989\n",
      "Step 21200: Loss = 0.563817233645691\n",
      "Step 21300: Loss = 0.5636306313449788\n",
      "Step 21400: Loss = 0.5634469355350343\n",
      "Step 21500: Loss = 0.5633170783644499\n",
      "Step 21600: Loss = 0.5631630260469737\n",
      "Step 21700: Loss = 0.5629840809367769\n",
      "Step 21800: Loss = 0.5628194100170507\n",
      "Step 21900: Loss = 0.5627051630316804\n",
      "Step 22000: Loss = 0.5624925384087996\n",
      "Step 22100: Loss = 0.5622837910217937\n",
      "Step 22200: Loss = 0.5621230547170382\n",
      "Step 22300: Loss = 0.5619108530384542\n",
      "Step 22400: Loss = 0.5617426204242344\n",
      "Step 22500: Loss = 0.5615950679249234\n",
      "Step 22600: Loss = 0.5614098528528636\n",
      "Step 22700: Loss = 0.5612801311864202\n",
      "Step 22800: Loss = 0.561116684449085\n",
      "Step 22900: Loss = 0.5609601244395477\n",
      "Step 23000: Loss = 0.560839823163074\n",
      "Step 23100: Loss = 0.5607071816366472\n",
      "Step 23200: Loss = 0.5605542269580324\n",
      "Step 23300: Loss = 0.5603842301353364\n",
      "Step 23400: Loss = 0.5602729419612477\n",
      "Step 23500: Loss = 0.5601298289438511\n",
      "Step 23600: Loss = 0.5599519128188238\n",
      "Step 23700: Loss = 0.5598186388989038\n",
      "Step 23800: Loss = 0.5596748163732661\n",
      "Step 23900: Loss = 0.5595617976772237\n",
      "Step 24000: Loss = 0.5594012087546288\n",
      "Step 24100: Loss = 0.5592344018384134\n",
      "Step 24200: Loss = 0.5590882963865749\n",
      "Step 24300: Loss = 0.5589442473049027\n",
      "Step 24400: Loss = 0.5588053058332108\n",
      "Step 24500: Loss = 0.5586830339772361\n",
      "Step 24600: Loss = 0.5585534864264291\n",
      "Step 24700: Loss = 0.5583816992259218\n",
      "Step 24800: Loss = 0.5582490135777382\n",
      "Step 24900: Loss = 0.5580768755856288\n",
      "Step 25000: Loss = 0.5579109784126282\n",
      "Step 25100: Loss = 0.5577467963811886\n",
      "Step 25200: Loss = 0.5575955945478073\n",
      "Step 25300: Loss = 0.5574792239647138\n",
      "Step 25400: Loss = 0.5573135140655547\n",
      "Step 25500: Loss = 0.5571581139669699\n",
      "Epoch 1/1, Average training loss: 0.557147338339079\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/venv/nltk_data'\n    - '/opt/venv/share/nltk_data'\n    - '/opt/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Uncomment to use custom training loop instead of the Trainer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m custom_model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m custom_model \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 111\u001b[0m, in \u001b[0;36mcustom_training_loop\u001b[0;34m(model, tokenizer, train_dataset, val_dataset, num_epochs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(decoded_labels)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Process predictions and references for ROUGE\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m processed_preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent_tokenize(pred\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m all_preds]\n\u001b[1;32m    112\u001b[0m processed_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent_tokenize(label\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m all_labels]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Compute metrics directly with processed text\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 111\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(decoded_labels)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Process predictions and references for ROUGE\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m processed_preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m all_preds]\n\u001b[1;32m    112\u001b[0m processed_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent_tokenize(label\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m all_labels]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Compute metrics directly with processed text\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/venv/nltk_data'\n    - '/opt/venv/share/nltk_data'\n    - '/opt/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to use custom training loop instead of the Trainer\n",
    "custom_model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "custom_model = custom_training_loop(\n",
    "    custom_model, \n",
    "    tokenizer, \n",
    "    tokenized_datasets[\"train\"], \n",
    "    tokenized_datasets[\"validation\"], \n",
    "    num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, model, tokenizer, max_length=MAX_TARGET_LENGTH):\n",
    "    \"\"\"Generate a summary for the given text.\"\"\"\n",
    "    # Prepare input\n",
    "    input_text = PREFIX + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=MAX_SOURCE_LENGTH, truncation=True).to(device)\n",
    "    \n",
    "    # Generate\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        length_penalty=0.6,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = dataset[\"test\"].select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Document (truncated): Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\n",
      "Workers at the charity claim investment in housing...\n",
      "Reference summary: There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\n",
      "Generated summary: prison link cymru says some ex-offenders are living rough for up to a year . charity says investment in housing would be cheaper than jailing homeless repeat offenders . the government says more people than ever are getting help to address housing problems .\n",
      "ROUGE scores: {'rouge1': 0.27118644067796605, 'rouge2': 0.03508771929824562, 'rougeL': 0.13559322033898302, 'rougeLsum': 0.13559322033898302}\n",
      "\n",
      "Example 2:\n",
      "Document (truncated): Officers searched properties in the Waterfront Park and Colonsay View areas of the city on Wednesday.\n",
      "Detectives said three firearms, ammunition and a five-figure sum of money were recovered.\n",
      "A 26-yea...\n",
      "Reference summary: A man has appeared in court after firearms, ammunition and cash were seized by police in Edinburgh.\n",
      "Generated summary: three firearms, ammunition and a five-figure sum of money were recovered . a 26-year-old man who was arrested and charged appeared at Edinburgh Sheriff Court .\n",
      "ROUGE scores: {'rouge1': 0.409090909090909, 'rouge2': 0.09523809523809525, 'rougeL': 0.22727272727272727, 'rougeLsum': 0.22727272727272727}\n",
      "\n",
      "Example 3:\n",
      "Document (truncated): Jordan Hill, Brittany Covington and Tesfaye Cooper, all 18, and Tanishia Covington, 24, appeared in a Chicago court on Friday.\n",
      "The four have been charged with hate crimes and aggravated kidnapping and...\n",
      "Reference summary: Four people accused of kidnapping and torturing a mentally disabled man in a \"racially motivated\" attack streamed on Facebook have been denied bail.\n",
      "Generated summary: four charged with hate crimes and aggravated kidnapping and battery . online fundraiser for victim has collected $51,000 (42,500) so far . judge asks: \"where was your sense of decency?\"\n",
      "ROUGE scores: {'rouge1': 0.15094339622641512, 'rouge2': 0.0392156862745098, 'rougeL': 0.11320754716981132, 'rougeLsum': 0.11320754716981132}\n",
      "\n",
      "Example 4:\n",
      "Document (truncated): The 48-year-old former Arsenal goalkeeper played for the Royals for four years.\n",
      "He was appointed youth academy director in 2000 and has been director of football since 2003.\n",
      "A West Brom statement said...\n",
      "Reference summary: West Brom have appointed Nicky Hammond as technical director, ending his 20-year association with Reading.\n",
      "Generated summary: former arsenal goalkeeper has been director of football since 2003 . he was appointed youth academy director in 2000 .\n",
      "ROUGE scores: {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "\n",
      "Example 5:\n",
      "Document (truncated): Restoring the function of the organ - which helps control blood sugar levels - reversed symptoms of diabetes in animal experiments.\n",
      "The study, published in the journal Cell, says the diet reboots the ...\n",
      "Reference summary: The pancreas can be triggered to regenerate itself through a type of fasting diet, say US researchers.\n",
      "Generated summary: mice put on a modified form of the \"fasting-mimicking diet\" they spend five days on a low calorie, low protein, low carbohydrate but high unsaturated-fat diet . they then have 25 days eating what they want - so overall it mimics\n",
      "ROUGE scores: {'rouge1': 0.17241379310344826, 'rouge2': 0.0, 'rougeL': 0.13793103448275862, 'rougeLsum': 0.13793103448275862}\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(test_samples):\n",
    "    document = sample[\"document\"]\n",
    "    reference_summary = sample[\"summary\"]\n",
    "    \n",
    "    # Generate summary\n",
    "    generated_summary = generate_summary(document, model, tokenizer)\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Document (truncated): {document[:200]}...\")\n",
    "    print(f\"Reference summary: {reference_summary}\")\n",
    "    print(f\"Generated summary: {generated_summary}\")\n",
    "    \n",
    "    # Calculate ROUGE for individual example\n",
    "    rouge_result = rouge_metric.compute(\n",
    "        predictions=[generated_summary],\n",
    "        references=[reference_summary],\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"ROUGE scores: {rouge_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, test_dataset, tokenizer, batch_size=4):\n",
    "    \"\"\"Evaluate the model on the full test set.\"\"\"\n",
    "    # Preprocess test set\n",
    "    preprocessed_test = test_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=test_dataset.column_names,\n",
    "        desc=\"Preprocessing test set\",\n",
    "    )\n",
    "    \n",
    "    # Create test dataloader\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        preprocessed_test,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    \n",
    "    # Generate summaries for entire test set\n",
    "    model.eval()\n",
    "    all_generated_summaries = []\n",
    "    all_reference_summaries = []\n",
    "    \n",
    "    # Original test data for reference summaries\n",
    "    original_test_data = dataset[\"test\"]\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(test_dataloader, desc=\"Generating summaries\")):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=MAX_TARGET_LENGTH,\n",
    "                num_beams=4,\n",
    "                length_penalty=0.6,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            \n",
    "            # Decode generated summaries\n",
    "            decoded_summaries = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            all_generated_summaries.extend(decoded_summaries)\n",
    "            \n",
    "            # Get reference summaries from original dataset\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min(start_idx + batch_size, len(original_test_data))\n",
    "            reference_summaries = [original_test_data[j][\"summary\"] for j in range(start_idx, end_idx)]\n",
    "            all_reference_summaries.extend(reference_summaries)\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    rouge_results = rouge_metric.compute(\n",
    "        predictions=all_generated_summaries,\n",
    "        references=all_reference_summaries,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    \n",
    "    # Format results for display\n",
    "    formatted_results = {k: round(v * 100, 2) for k, v in rouge_results.items()}\n",
    "    return formatted_results, all_generated_summaries, all_reference_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19a59d420814cb3b62980cd3f5a2f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing test set:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748f767b70f24b738757a05a81ec86e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating summaries:   0%|          | 0/2834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "test_results, generated_summaries, reference_summaries = evaluate_on_test_set(\n",
    "    model, dataset[\"test\"], tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation results:\n",
      "{'rouge1': 20.45, 'rouge2': 3.09, 'rougeL': 13.87, 'rougeLsum': 13.87}\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set evaluation results:\")\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_generation_strategies(text, model, tokenizer, max_length=MAX_TARGET_LENGTH):\n",
    "    \"\"\"Compare different generation strategies for the given text.\"\"\"\n",
    "    input_text = PREFIX + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=MAX_SOURCE_LENGTH, truncation=True).to(device)\n",
    "    \n",
    "    # Strategy 1: Standard Beam Search\n",
    "    outputs_beam = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "    # Strategy 2: Beam Search with Length Penalty\n",
    "    outputs_length_penalty = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        length_penalty=0.6,  # < 1.0 favors shorter sequences\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "    # Strategy 3: Diverse Beam Search\n",
    "    outputs_diverse_beam = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        num_beam_groups=4,\n",
    "        diversity_penalty=0.5,  # Promotes diversity between groups\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    \n",
    "    # Strategy 4: Top-p (Nucleus) Sampling\n",
    "    outputs_top_p = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        top_p=0.92,\n",
    "        top_k=0,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    # Decode\n",
    "    summary_beam = tokenizer.decode(outputs_beam[0], skip_special_tokens=True)\n",
    "    summary_length_penalty = tokenizer.decode(outputs_length_penalty[0], skip_special_tokens=True)\n",
    "    summary_diverse_beam = tokenizer.decode(outputs_diverse_beam[0], skip_special_tokens=True)\n",
    "    summary_top_p = tokenizer.decode(outputs_top_p[0], skip_special_tokens=True)\n",
    "    \n",
    "    return {\n",
    "        \"standard_beam\": summary_beam,\n",
    "        \"length_penalty\": summary_length_penalty,\n",
    "        \"diverse_beam\": summary_diverse_beam,\n",
    "        \"top_p_sampling\": summary_top_p\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc = dataset[\"test\"][10][\"document\"]\n",
    "reference = dataset[\"test\"][10][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing different generation strategies:\n",
      "Document (truncated): The move is in response to an 8m cut in the subsidy received from the Department of Employment and Learning (DEL).\n",
      "The cut in undergraduate places will come into effect from September 2015.\n",
      "Job losse...\n",
      "Reference summary: Queen's University Belfast is cutting 236 jobs and 290 student places due to a funding reduction.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparing different generation strategies:\")\n",
    "print(f\"Document (truncated): {sample_doc[:200]}...\")\n",
    "print(f\"Reference summary: {reference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_results = compare_generation_strategies(sample_doc, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STANDARD_BEAM strategy:\n",
      "there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff . the university aims to reduce the number of student places by 1,010 over the next three years . there are no immediate plans to close departments or courses .\n",
      "ROUGE scores: {'rouge1': 15.38, 'rouge2': 3.17, 'rougeL': 15.38, 'rougeLsum': 15.38}\n",
      "\n",
      "LENGTH_PENALTY strategy:\n",
      "there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff . the university aims to reduce the number of student places by 1,010 over the next three years . there are no immediate plans to close departments or courses .\n",
      "ROUGE scores: {'rouge1': 15.38, 'rouge2': 3.17, 'rougeL': 15.38, 'rougeLsum': 15.38}\n",
      "\n",
      "DIVERSE_BEAM strategy:\n",
      "the move is in response to an 8m cut in the subsidy received from the department of employment and learning (DEL) there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff . there are no immediate plans to close departments or courses\n",
      "ROUGE scores: {'rouge1': 17.65, 'rouge2': 0.0, 'rougeL': 14.71, 'rougeLsum': 14.71}\n",
      "\n",
      "TOP_P_SAMPLING strategy:\n",
      "the move is in response to an 8m cut in the subsidy received from the department of employment and learning . the cuts will come into effect from September 2015 . there are currently around 17,000 full-time undergraduates and 3,800 staff .\n",
      "ROUGE scores: {'rouge1': 13.56, 'rouge2': 0.0, 'rougeL': 10.17, 'rougeLsum': 10.17}\n"
     ]
    }
   ],
   "source": [
    "for strategy, summary in generation_results.items():\n",
    "    print(f\"\\n{strategy.upper()} strategy:\")\n",
    "    print(summary)\n",
    "    \n",
    "    # Calculate ROUGE for individual strategy\n",
    "    rouge_result = rouge_metric.compute(\n",
    "        predictions=[summary],\n",
    "        references=[reference],\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    \n",
    "    formatted_rouge = {k: round(v * 100, 2) for k, v in rouge_result.items()}\n",
    "    print(f\"ROUGE scores: {formatted_rouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_task_prefixes(text, model, tokenizer, max_length=MAX_TARGET_LENGTH):\n",
    "    \"\"\"Compare different task prefixes for T5 summarization.\"\"\"\n",
    "    prefixes = [\n",
    "        \"summarize: \",\n",
    "        \"generate summary: \",\n",
    "        \"tl;dr: \",\n",
    "        \"summarization: \",\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for prefix in prefixes:\n",
    "        input_text = prefix + text\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=MAX_SOURCE_LENGTH, truncation=True).to(device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            length_penalty=0.6,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        \n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        results[prefix] = summary\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing different T5 task prefixes:\n",
      "\n",
      "Prefix: 'summarize: '\n",
      "Generated summary: there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff . the university aims to reduce the number of student places by 1,010 over the next three years . there are no immediate plans to close departments or courses .\n",
      "ROUGE scores: {'rouge1': 15.38, 'rouge2': 3.17, 'rougeL': 15.38, 'rougeLsum': 15.38}\n",
      "\n",
      "Prefix: 'generate summary: '\n",
      "Generated summary: queen's vice-chancellor Patrick Johnston said the cuts had the potential to damage the reputation of the university . there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff .\n",
      "ROUGE scores: {'rouge1': 25.0, 'rouge2': 3.7, 'rougeL': 17.86, 'rougeLsum': 17.86}\n",
      "\n",
      "Prefix: 'tl;dr: '\n",
      "Generated summary: queen's vice-chancellor Patrick Johnston says the cuts have the potential to damage the reputation of the university . there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff . the university aims to reduce the number of student places by\n",
      "ROUGE scores: {'rouge1': 23.88, 'rouge2': 6.15, 'rougeL': 17.91, 'rougeLsum': 17.91}\n",
      "\n",
      "Prefix: 'summarization: '\n",
      "Generated summary: queen's vice-chancellor Patrick Johnston said the cuts had the potential to damage the reputation of the university . there are currently around 17,000 full-time undergraduate and postgraduate students at the university, and around 3,800 staff .\n",
      "ROUGE scores: {'rouge1': 25.0, 'rouge2': 3.7, 'rougeL': 17.86, 'rougeLsum': 17.86}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparing different T5 task prefixes:\")\n",
    "prefix_results = compare_task_prefixes(sample_doc, model, tokenizer)\n",
    "\n",
    "for prefix, summary in prefix_results.items():\n",
    "    print(f\"\\nPrefix: '{prefix}'\")\n",
    "    print(f\"Generated summary: {summary}\")\n",
    "    \n",
    "    # Calculate ROUGE for individual prefix\n",
    "    rouge_result = rouge_metric.compute(\n",
    "        predictions=[summary],\n",
    "        references=[reference],\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    \n",
    "    formatted_rouge = {k: round(v * 100, 2) for k, v in rouge_result.items()}\n",
    "    print(f\"ROUGE scores: {formatted_rouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./model_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model_export/tokenizer/tokenizer_config.json',\n",
       " './model_export/tokenizer/special_tokens_map.json',\n",
       " './model_export/tokenizer/spiece.model',\n",
       " './model_export/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./model_export/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model_export/model\"\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1912571,
     "sourceId": 3140615,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
