{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2530487,"sourceType":"datasetVersion","datasetId":1533360}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport wandb\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport seaborn as sns\nimport torch.nn as nn\n\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import ViTForImageClassification\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom kaggle_secrets import UserSecretsClient\nfrom tqdm.auto import tqdm as tqdm_progress","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:01.627522Z","iopub.execute_input":"2025-03-26T16:47:01.627818Z","iopub.status.idle":"2025-03-26T16:47:27.451788Z","shell.execute_reply.started":"2025-03-26T16:47:01.627785Z","shell.execute_reply":"2025-03-26T16:47:27.450898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using {device} device\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.452736Z","iopub.execute_input":"2025-03-26T16:47:27.453294Z","iopub.status.idle":"2025-03-26T16:47:27.509968Z","shell.execute_reply.started":"2025-03-26T16:47:27.453269Z","shell.execute_reply":"2025-03-26T16:47:27.508976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def init_wandb(project_name=\"vit-retinal-disease-cls\", config=None):\n    try:\n        user_secrets = UserSecretsClient()\n\n        wandb_api_key = user_secrets.get_secret(\"wandb\")\n        os.environ['WANDB_API_KEY'] = wandb_api_key\n\n        wandb.login(key=wandb_api_key)\n        \n        run = wandb.init(\n            project=project_name,\n            config=config,\n            tags=[\"ViT\", \"Retinal Disease\"],\n            notes=\"Vision Transformer on Retinal Disease Classification Dataset\"\n        )\n        print(\"W&B successfully initialized\")\n        return run\n    except Exception as e:\n        print(f\"Error initializing W&B: {str(e)}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.511055Z","iopub.execute_input":"2025-03-26T16:47:27.511352Z","iopub.status.idle":"2025-03-26T16:47:27.527229Z","shell.execute_reply.started":"2025-03-26T16:47:27.511318Z","shell.execute_reply":"2025-03-26T16:47:27.526282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RetinalDiseaseDataset(Dataset):\n    def __init__(self, csv_file, img_dir, transform=None):\n        self.labels_frame = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.diseases = [col for col in self.labels_frame.columns if col not in ['ID', 'Disease_Risk']]\n\n        self.transform = transform or transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                                 std=[0.229, 0.224, 0.225])\n        ])\n\n    def __len__(self):\n        return len(self.labels_frame)\n\n    def __getitem__(self, idx):\n        img_filename = str(self.labels_frame.iloc[idx, 0])\n        \n        if not img_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n            img_filename += '.png'\n        \n        img_name = os.path.join(self.img_dir, img_filename)\n        \n        if not os.path.exists(img_name):\n            img_name = os.path.join(self.img_dir, str(self.labels_frame.iloc[0, 0]) + '.png')\n        \n        image = Image.open(img_name).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        labels = torch.tensor(\n            self.labels_frame.iloc[idx, 1:].values, \n            dtype=torch.float32\n        )\n        \n        return image, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.529494Z","iopub.execute_input":"2025-03-26T16:47:27.529789Z","iopub.status.idle":"2025-03-26T16:47:27.542639Z","shell.execute_reply.started":"2025-03-26T16:47:27.529761Z","shell.execute_reply":"2025-03-26T16:47:27.541797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_dataset_samples(dataloader, num_samples=12, title=\"Dataset Samples\"):\n    rows = int(np.ceil(np.sqrt(num_samples)))\n    cols = rows\n    \n    plt.figure(figsize=(15, 15))\n    plt.suptitle(title)\n    \n    images, labels = next(iter(dataloader))\n    \n    for i in range(min(num_samples, len(images))):\n        plt.subplot(rows, cols, i+1)\n        \n        if isinstance(images[i], torch.Tensor):\n            img = images[i].cpu().permute(1, 2, 0).numpy()\n        else:\n            img = images[i]\n        \n        img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n        img = np.clip(img, 0, 1)\n        \n        plt.imshow(img)\n        plt.title(f\"Labels: {labels[i].numpy()}\")\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.544065Z","iopub.execute_input":"2025-03-26T16:47:27.544288Z","iopub.status.idle":"2025-03-26T16:47:27.565236Z","shell.execute_reply.started":"2025-03-26T16:47:27.544268Z","shell.execute_reply":"2025-03-26T16:47:27.56407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def analyze_retinal_dataset(csv_path):\n    df = pd.read_csv(csv_path)\n    diseases = [col for col in df.columns if col not in ['ID', 'Disease_Risk']]\n    \n    total_samples = len(df)\n    class_distribution = df[diseases].sum().sort_values(ascending=False)\n    percentage_per_label = (class_distribution / total_samples * 100).round(2)\n    \n    disease_correlation = df[diseases].corr()\n    \n    multi_label_count = (df[diseases].sum(axis=1) > 1).sum()\n    multi_label_percentage = (multi_label_count / total_samples * 100).round(2)\n    \n    plt.figure(figsize=(20, 15))\n    \n    plt.subplot(2, 2, 1)\n    percentage_per_label.plot(kind='bar')\n    plt.title('Disease Distribution')\n    plt.xlabel('Disease')\n    plt.ylabel('% of Dataset')\n    plt.xticks(rotation=90)\n    \n    plt.subplot(2, 2, 2)\n    sns.heatmap(disease_correlation, cmap='coolwarm', center=0, \n                annot=False, cbar_kws={'label': 'Correlation'})\n    plt.title('Disease Correlation')\n    \n    plt.subplot(2, 2, 3)\n    percentage_per_label.head(10).plot(kind='pie', autopct='%1.1f%%')\n    plt.title('Top-10 Diseases')\n    \n    plt.subplot(2, 2, 4)\n    labels_count = df[diseases].sum(axis=1)\n    labels_count.plot(kind='hist', bins=range(1, labels_count.max()+2))\n    plt.title('Distribution of Labels per Image')\n    plt.xlabel('Number of Diseases')\n    plt.ylabel('Frequency')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\nDataset Analysis Report\")\n    print(f\"Total number of samples: {total_samples}\")\n    print(f\"\\nSamples with multiple labels: {multi_label_count} ({multi_label_percentage}%)\")\n    \n    print(\"\\nTop-5 Most Common Diseases:\")\n    for disease, percentage in percentage_per_label.head().items():\n        print(f\"{disease}: {percentage}%\")\n    \n    print(\"\\nTop-5 Least Common Diseases:\")\n    for disease, percentage in percentage_per_label.tail().items():\n        print(f\"{disease}: {percentage}%\")\n    \n    return {\n        'total_samples': total_samples,\n        'multi_label_samples': multi_label_count,\n        'multi_label_percentage': multi_label_percentage,\n        'most_common_diseases': percentage_per_label.head(),\n        'least_common_diseases': percentage_per_label.tail()\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.565972Z","iopub.execute_input":"2025-03-26T16:47:27.566272Z","iopub.status.idle":"2025-03-26T16:47:27.584327Z","shell.execute_reply.started":"2025-03-26T16:47:27.566238Z","shell.execute_reply":"2025-03-26T16:47:27.583601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataloader(csv_path, img_dir, batch_size=32, shuffle=True, train=True):\n    transform_list = [\n        transforms.Resize((224, 224))\n    ]\n    \n    if train:\n        transform_list.extend([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10)\n        ])\n    \n    transform_list.extend([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n    ])\n\n    transform = transforms.Compose(transform_list)\n\n    dataset = RetinalDiseaseDataset(\n        csv_file=csv_path, \n        img_dir=img_dir,\n        transform=transform\n    )\n    \n    return DataLoader(\n        dataset, \n        batch_size=batch_size, \n        shuffle=shuffle,\n        num_workers=0,\n        pin_memory=True\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.585238Z","iopub.execute_input":"2025-03-26T16:47:27.585536Z","iopub.status.idle":"2025-03-26T16:47:27.602393Z","shell.execute_reply.started":"2025-03-26T16:47:27.5855Z","shell.execute_reply":"2025-03-26T16:47:27.601584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n    \n    def forward(self, inputs, targets):\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        return torch.mean(F_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.603235Z","iopub.execute_input":"2025-03-26T16:47:27.603507Z","iopub.status.idle":"2025-03-26T16:47:27.619774Z","shell.execute_reply.started":"2025-03-26T16:47:27.603475Z","shell.execute_reply":"2025-03-26T16:47:27.618926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_model(num_classes=46, pretrained=True):\n    if pretrained:\n        model = ViTForImageClassification.from_pretrained(\n            'google/vit-base-patch16-224', \n            num_labels=num_classes,\n            ignore_mismatched_sizes=True\n        )\n    else:\n        model = ViTForImageClassification.from_pretrained(\n            'google/vit-base-patch16-224', \n            num_labels=num_classes,\n            num_hidden_layers=6,\n            hidden_dropout_prob=0.1,\n            attention_probs_dropout_prob=0.1\n        )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.620558Z","iopub.execute_input":"2025-03-26T16:47:27.62082Z","iopub.status.idle":"2025-03-26T16:47:27.640755Z","shell.execute_reply.started":"2025-03-26T16:47:27.620795Z","shell.execute_reply":"2025-03-26T16:47:27.639838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def log_image_predictions(model, val_loader, device, wandb_run=None):\n    model.eval()\n    images, true_labels = next(iter(val_loader))\n    images = images.to(device)\n    true_labels = true_labels.cpu().numpy()\n    \n    with torch.no_grad():\n        outputs = model(images).logits\n        pred_probs = torch.sigmoid(outputs).cpu().numpy()\n        pred_labels = (pred_probs > 0.5).astype(int)\n    \n    if wandb_run:\n        wandb_images = []\n        for i in range(min(16, len(images))):\n            img = images[i].cpu().permute(1, 2, 0).numpy()\n            img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n            img = np.clip(img, 0, 1)\n            \n            true_diseases = np.where(true_labels[i])[0]\n            pred_diseases = np.where(pred_labels[i])[0]\n            \n            wandb_image = wandb.Image(\n                img, \n                caption=f\"True: {true_diseases}, Pred: {pred_diseases}\"\n            )\n            wandb_images.append(wandb_image)\n        \n        wandb.log({\"sample_predictions\": wandb_images})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.641546Z","iopub.execute_input":"2025-03-26T16:47:27.641833Z","iopub.status.idle":"2025-03-26T16:47:27.655773Z","shell.execute_reply.started":"2025-03-26T16:47:27.641807Z","shell.execute_reply":"2025-03-26T16:47:27.654959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, device, epochs=20):\n    try:\n        wandb_run = init_wandb(config={\n            \"learning_rate\": 1e-4,\n            \"epochs\": epochs,\n            \"batch_size\": train_loader.batch_size\n        })\n    except Exception as e:\n        print(f\"WandB initialization error: {e}\")\n        wandb_run = None\n\n    criterion = FocalLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        train_preds, train_labels = [], []\n        \n        pbar = tqdm_progress(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        \n        for images, labels in pbar:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images).logits\n            loss = criterion(outputs, labels.float())\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            \n            preds = torch.sigmoid(outputs).detach().cpu().numpy()\n            train_preds.append(preds)\n            train_labels.append(labels.cpu().numpy())\n            \n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n        \n        train_preds = np.concatenate(train_preds)\n        train_labels = np.concatenate(train_labels)\n        train_pred_binary = (train_preds > 0.5).astype(int)\n        \n        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(\n            train_labels, train_pred_binary, average='micro')\n        \n        # Валидация\n        model.eval()\n        val_loss = 0\n        val_preds, val_labels = [], []\n        \n        with torch.no_grad():\n            val_pbar = tqdm_progress(val_loader, desc=f\"Validation {epoch+1}/{epochs}\")\n            for images, labels in val_pbar:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images).logits\n                val_loss += criterion(outputs, labels.float()).item()\n                \n                preds = torch.sigmoid(outputs).detach().cpu().numpy()\n                val_preds.append(preds)\n                val_labels.append(labels.cpu().numpy())\n                \n                val_pbar.set_postfix({'loss': f'{val_loss/len(val_preds):.4f}'})\n        \n        val_preds = np.concatenate(val_preds)\n        val_labels = np.concatenate(val_labels)\n        val_pred_binary = (val_preds > 0.5).astype(int)\n        \n        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n            val_labels, val_pred_binary, average='micro')\n        \n        if wandb_run:\n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": train_loss/len(train_loader),\n                \"val_loss\": val_loss/len(val_loader),\n                \"train_precision\": train_precision,\n                \"train_recall\": train_recall,\n                \"train_f1\": train_f1,\n                \"val_precision\": val_precision,\n                \"val_recall\": val_recall,\n                \"val_f1\": val_f1\n            })\n        \n        print(f\"Epoch {epoch+1}:\")\n        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n        print(f\"Val Loss: {val_loss/len(val_loader):.4f}\")\n        print(f\"Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}\")\n        \n        #if train_loss/len(train_loader) < 0.01:\n        #    print(\"Early stopping due to low loss\")\n        #    break\n    \n    if wandb_run:\n        wandb.finish()\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:51:53.306802Z","iopub.execute_input":"2025-03-26T16:51:53.307196Z","iopub.status.idle":"2025-03-26T16:51:53.319155Z","shell.execute_reply.started":"2025-03-26T16:51:53.307158Z","shell.execute_reply":"2025-03-26T16:51:53.318373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/retinal-disease-classification\"\n\nTRAIN_CSV = os.path.join(BASE_PATH, \"Training_Set/Training_Set/RFMiD_Training_Labels.csv\")\nTRAIN_IMG_DIR = os.path.join(BASE_PATH, \"Training_Set/Training_Set/Training\")\n\nVAL_CSV = os.path.join(BASE_PATH, \"Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv\")\nVAL_IMG_DIR = os.path.join(BASE_PATH, \"Evaluation_Set/Evaluation_Set/Validation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.673732Z","iopub.execute_input":"2025-03-26T16:47:27.674248Z","iopub.status.idle":"2025-03-26T16:47:27.692097Z","shell.execute_reply.started":"2025-03-26T16:47:27.674216Z","shell.execute_reply":"2025-03-26T16:47:27.691307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nVisualizing Training Dataset Samples\")\ntrain_loader = create_dataloader(TRAIN_CSV, TRAIN_IMG_DIR)\nvisualize_dataset_samples(train_loader, title=\"Training Dataset Samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:27.694531Z","iopub.execute_input":"2025-03-26T16:47:27.694726Z","iopub.status.idle":"2025-03-26T16:47:34.27776Z","shell.execute_reply.started":"2025-03-26T16:47:27.69471Z","shell.execute_reply":"2025-03-26T16:47:34.273218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nVisualizing Validation Dataset Samples\")\nval_loader = create_dataloader(VAL_CSV, VAL_IMG_DIR, train=False)\nvisualize_dataset_samples(val_loader, title=\"Validation Dataset Samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:34.279126Z","iopub.execute_input":"2025-03-26T16:47:34.279558Z","iopub.status.idle":"2025-03-26T16:47:42.186196Z","shell.execute_reply.started":"2025-03-26T16:47:34.279515Z","shell.execute_reply":"2025-03-26T16:47:42.185164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Analyzing Training Dataset\")\ntrain_analysis = analyze_retinal_dataset(TRAIN_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:42.187285Z","iopub.execute_input":"2025-03-26T16:47:42.187547Z","iopub.status.idle":"2025-03-26T16:47:43.95295Z","shell.execute_reply.started":"2025-03-26T16:47:42.187524Z","shell.execute_reply":"2025-03-26T16:47:43.952155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = create_model().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:47:43.953688Z","iopub.execute_input":"2025-03-26T16:47:43.953926Z","iopub.status.idle":"2025-03-26T16:47:46.974584Z","shell.execute_reply.started":"2025-03-26T16:47:43.953907Z","shell.execute_reply":"2025-03-26T16:47:46.973819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trained_model = train_model(model, train_loader, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:51:57.861978Z","iopub.execute_input":"2025-03-26T16:51:57.862282Z","iopub.status.idle":"2025-03-26T16:57:35.272567Z","shell.execute_reply.started":"2025-03-26T16:51:57.862261Z","shell.execute_reply":"2025-03-26T16:57:35.271541Z"}},"outputs":[],"execution_count":null}]}